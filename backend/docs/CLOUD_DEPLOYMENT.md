# RunningCoach í´ë¼ìš°ë“œ ë°°í¬ ê°€ì´ë“œ

## ğŸ¯ ì¶”ì²œ: Supabase (DB + Storage í†µí•©)

### ì•„í‚¤í…ì²˜
```
[Frontend - Vercel]
    â†“
[Backend API - Railway/Fly.io]
    â†“
[Supabase]
  â”œâ”€ PostgreSQL (í™œë™ ë°ì´í„°)
  â””â”€ Storage (FIT íŒŒì¼)
```

## Supabase ì„¤ì • (15ë¶„)

### 1. í”„ë¡œì íŠ¸ ìƒì„±
```bash
# supabase.comì—ì„œ í”„ë¡œì íŠ¸ ìƒì„± í›„
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=eyJxxx...
DATABASE_URL=postgresql://postgres:[PASSWORD]@db.xxx.supabase.co:5432/postgres
```

### 2. Storage Bucket ì„¤ì •
```sql
-- Supabase Dashboard SQL Editor
INSERT INTO storage.buckets (id, name, public)
VALUES ('fit-files', 'fit-files', false);

-- RLS ì •ì±… (ì‚¬ìš©ìë³„ ì ‘ê·¼ ì œí•œ)
CREATE POLICY "Users can upload their own FIT files"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (bucket_id = 'fit-files' AND
            auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY "Users can view their own FIT files"
ON storage.objects FOR SELECT
TO authenticated
USING (bucket_id = 'fit-files' AND
       auth.uid()::text = (storage.foldername(name))[1]);
```

### 3. ì„œë¹„ìŠ¤ í†µí•© ì½”ë“œ

```python
# app/services/supabase_storage.py
from supabase import create_client, Client
from typing import Optional, Dict
import os

class SupabaseStorageService:
    def __init__(self):
        self.client: Client = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_SERVICE_KEY")  # Service key for backend
        )
        self.bucket = "fit-files"

    async def upload_fit(
        self,
        user_id: int,
        activity_id: int,
        fit_data: bytes
    ) -> Dict[str, str]:
        """Upload FIT file to Supabase Storage."""

        # Path: user_id/activity_id.fit
        path = f"{user_id}/{activity_id}.fit"

        # Upload
        response = self.client.storage.from_(self.bucket).upload(
            path,
            fit_data,
            {"content-type": "application/octet-stream"}
        )

        # Generate signed URL (1 hour)
        signed_url = self.client.storage.from_(self.bucket)\
            .create_signed_url(path, 3600)

        return {
            "path": path,
            "signed_url": signed_url["signedURL"],
            "size": len(fit_data)
        }

    async def get_fit(
        self,
        user_id: int,
        activity_id: int
    ) -> Optional[bytes]:
        """Download FIT file from Supabase Storage."""

        path = f"{user_id}/{activity_id}.fit"

        # Download
        response = self.client.storage.from_(self.bucket)\
            .download(path)

        return response

    def get_public_url(self, path: str) -> str:
        """Get public URL (if bucket is public)."""
        return self.client.storage.from_(self.bucket)\
            .get_public_url(path)
```

### 4. ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/migrate_to_supabase.py
import asyncio
from pathlib import Path
from supabase import create_client

async def migrate_to_supabase():
    """Migrate existing FIT files to Supabase Storage."""

    # Initialize clients
    supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

    # Get all activities with FIT files
    activities = await db.query("""
        SELECT id, user_id, fit_file_path, fit_file_content
        FROM activities
        WHERE fit_file_path IS NOT NULL
           OR fit_file_content IS NOT NULL
    """)

    for activity in activities:
        # Get FIT data
        if activity.fit_file_content:
            # From DB
            fit_data = decompress(activity.fit_file_content)
        else:
            # From filesystem
            fit_data = Path(activity.fit_file_path).read_bytes()

        # Upload to Supabase
        path = f"{activity.user_id}/{activity.id}.fit"
        supabase.storage.from_("fit-files").upload(path, fit_data)

        # Update record
        await db.execute("""
            UPDATE activities
            SET storage_path = %s, storage_provider = 'supabase'
            WHERE id = %s
        """, (path, activity.id))

        print(f"âœ“ Migrated activity {activity.id}")

if __name__ == "__main__":
    asyncio.run(migrate_to_supabase())
```

## Railway/Fly.io ë°°í¬ (Backend)

### Railway (ì¶”ì²œ)
```bash
# railway.toml
[build]
  builder = "DOCKERFILE"

[deploy]
  startCommand = "uvicorn app.main:app --host 0.0.0.0 --port $PORT"

# ë°°í¬
railway login
railway link
railway up
```

### Fly.io
```toml
# fly.toml
app = "runningcoach-api"

[env]
  PORT = "8080"

[[services]]
  internal_port = 8080
  protocol = "tcp"

  [[services.ports]]
    handlers = ["http"]
    port = 80

  [[services.ports]]
    handlers = ["tls", "http"]
    port = 443

# ë°°í¬
fly launch
fly deploy
```

## Vercel ë°°í¬ (Frontend)

```json
// vercel.json
{
  "rewrites": [
    {
      "source": "/api/:path*",
      "destination": "https://runningcoach-api.railway.app/api/:path*"
    }
  ]
}
```

```bash
# ë°°í¬
vercel
```

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

### Backend (.env.production)
```bash
# Supabase
DATABASE_URL=postgresql://postgres:[PASSWORD]@db.xxx.supabase.co:5432/postgres
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_KEY=eyJxxx...  # Service role key
SUPABASE_ANON_KEY=eyJxxx...     # Public anon key

# Redis (Upstash)
REDIS_URL=redis://default:xxx@xxx.upstash.io:6379

# Auth
SESSION_SECRET=xxx
SECRET_KEY=xxx
COOKIE_SECURE=true
COOKIE_SAMESITE=none

# CORS
CORS_ORIGINS=https://runningcoach.vercel.app
```

### Frontend (.env.production)
```bash
VITE_API_BASE_URL=https://runningcoach-api.railway.app
VITE_SUPABASE_URL=https://xxx.supabase.co
VITE_SUPABASE_ANON_KEY=eyJxxx...
```

## ë¹„ìš© ë¶„ì„ (ì›”)

### Option 1: Supabase + Railway
- Supabase Free: $0
- Railway (API): $5
- **ì´: $5/ì›”**

### Option 2: Supabase Pro + Vercel
- Supabase Pro: $25
- Vercel Pro: $20
- **ì´: $45/ì›”** (í”„ë¡œë•ì…˜ê¸‰)

### Option 3: All-in-One PaaS
- Render.com: $7 (DB) + $7 (API) = $14/ì›”
- Fly.io: $7 (DB) + $0 (API) = $7/ì›”

## ëª¨ë‹ˆí„°ë§

### Supabase Dashboard
- ì‹¤ì‹œê°„ DB ì¿¼ë¦¬ ëª¨ë‹ˆí„°ë§
- Storage ì‚¬ìš©ëŸ‰ ì¶”ì 
- API ìš”ì²­ í†µê³„

### Uptime ëª¨ë‹ˆí„°ë§
```javascript
// UptimeRobot ë˜ëŠ” Better Uptime ì„¤ì •
const endpoints = [
  'https://api.runningcoach.com/health',
  'https://runningcoach.com'
];
```

## ë°±ì—… ì „ëµ

### ìë™ ë°±ì—… (Supabase)
- ì¼ì¼ ìë™ ë°±ì—… (7ì¼ ë³´ê´€)
- Point-in-time recovery (Pro)

### ìˆ˜ë™ ë°±ì—…
```bash
# DB ë°±ì—…
pg_dump $DATABASE_URL > backup_$(date +%Y%m%d).sql

# Storage ë°±ì—… (rclone)
rclone sync supabase:fit-files ./backups/fit-files
```

## ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] HTTPS ê°•ì œ
- [x] í™˜ê²½ ë³€ìˆ˜ ë¶„ë¦¬
- [x] RLS (Row Level Security) í™œì„±í™”
- [x] API Rate Limiting
- [x] CORS ì„¤ì •
- [x] SQL Injection ë°©ì§€
- [x] File Upload í¬ê¸° ì œí•œ
- [x] Auth Token ë§Œë£Œ ì„¤ì •

## ê²°ë¡ 

**ì¶”ì²œ ìŠ¤íƒ:**
1. **Supabase** (DB + Storage) - í†µí•© ê´€ë¦¬
2. **Railway/Fly.io** (Backend API) - ê°„í¸ ë°°í¬
3. **Vercel** (Frontend) - ë¹ ë¥¸ CDN

**ì¥ì :**
- ì–´ë””ì„œë“  ì ‘ê·¼ ê°€ëŠ¥
- ìë™ ë°±ì—…
- ë¬´ë£Œ ì‹œì‘ â†’ ì„±ì¥ ì‹œ ì—…ê·¸ë ˆì´ë“œ
- 5ë¶„ ë‚´ ë°°í¬ ê°€ëŠ¥

ì´ì œ ë¡œì»¬ì´ ì•„ë‹Œ í´ë¼ìš°ë“œì—ì„œ ì™„ì „íˆ êµ¬ë™ë©ë‹ˆë‹¤!